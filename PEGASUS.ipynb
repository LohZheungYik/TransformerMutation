{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-19T15:34:16.539494Z","iopub.status.busy":"2023-09-19T15:34:16.539052Z","iopub.status.idle":"2023-09-19T15:34:30.967111Z","shell.execute_reply":"2023-09-19T15:34:30.965478Z","shell.execute_reply.started":"2023-09-19T15:34:16.539465Z"},"trusted":true},"outputs":[],"source":["!pip install transformers sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:34:30.970271Z","iopub.status.busy":"2023-09-19T15:34:30.969611Z","iopub.status.idle":"2023-09-19T15:34:42.895035Z","shell.execute_reply":"2023-09-19T15:34:42.893926Z","shell.execute_reply.started":"2023-09-19T15:34:30.970206Z"},"trusted":true},"outputs":[],"source":["!pip install torchtext==0.6.0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:34:42.897123Z","iopub.status.busy":"2023-09-19T15:34:42.896760Z","iopub.status.idle":"2023-09-19T15:34:55.243277Z","shell.execute_reply":"2023-09-19T15:34:55.241972Z","shell.execute_reply.started":"2023-09-19T15:34:42.897088Z"},"trusted":true},"outputs":[],"source":["!pip install evaluate sacrebleu"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:34:55.248087Z","iopub.status.busy":"2023-09-19T15:34:55.247745Z","iopub.status.idle":"2023-09-19T15:34:55.259806Z","shell.execute_reply":"2023-09-19T15:34:55.258575Z","shell.execute_reply.started":"2023-09-19T15:34:55.248055Z"},"trusted":true},"outputs":[],"source":["# Specify the filename of loss file txt\n","output_filename = \"averageLosses.txt\"\n","\n","# Open the file in write mode\n","with open(output_filename, \"w\") as f:\n","    # Write a space character to the file\n","    f.write(\" \")\n","\n","print(f\"A space character has been written to {output_filename}.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:34:55.262155Z","iopub.status.busy":"2023-09-19T15:34:55.261724Z","iopub.status.idle":"2023-09-19T15:34:55.277095Z","shell.execute_reply":"2023-09-19T15:34:55.276127Z","shell.execute_reply.started":"2023-09-19T15:34:55.262105Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, PegasusForConditionalGeneration, AdamW\n","import torch\n","import csv\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Check if a GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Read data from train.tsv and create training examples\n","training_examples = []\n","\n","#TODO: REPLACE FOLLOWING WITH TRAINING DATA (TSV FILE) PATH\n","with open('/PATH/TO/TRAINING.TSV', 'r') as tsvfile:\n","    reader = csv.reader(tsvfile, delimiter='\\t')\n","    next(reader)  # Skip header row\n","    for row in reader:\n","        fixed_sentence = row[0]\n","        buggy_sentence = row[1]\n","        training_examples.append((fixed_sentence, buggy_sentence))\n","\n","# Load Pegasus tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\n","\n","model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n","\n","# Move models to GPU\n","model.to(device)\n","\n","# Define optimizer and loss function\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","#TODO: REPLACE THE FOLLOWING WITH LOSS FILE TXT PATH\n","loss_file = \"/PATH/TO/averageLosses.txt\"\n","\n","load = False\n","if load:\n","    #TODO: REPLACE THE FOLLOWING WITH MODEL TRAINING CHECKPOINT .PT FILE\n","    model.load_state_dict(torch.load(\"/PATH/TO/pegasusModel.pt\"))\n","\n","# Training loop\n","batch_size = 16\n","average_losses = []\n","for epoch in range(30):  # Number of epochs\n","    total_loss = 0.0\n","\n","    tokenized_example_subset = training_examples\n","\n","    # Shuffle the tokenized examples\n","    np.random.shuffle(tokenized_example_subset)\n","\n","    num_batches = len(tokenized_example_subset) // batch_size\n","\n","    for batch_idx in tqdm(range(num_batches), desc=f\"Epoch {epoch+1}\"):\n","        start_idx = batch_idx * batch_size\n","        end_idx = start_idx + batch_size\n","\n","        batch_examples = tokenized_example_subset[start_idx:end_idx]\n","\n","        input_code_tensors = []\n","        target_code_tensors = []\n","\n","        for example in batch_examples:\n","            tokenized_incorrect, tokenized_correct = example\n","\n","            # Tokenize using the Pegasus tokenizer\n","            encoded_inputs = tokenizer(tokenized_incorrect, padding='max_length', max_length=150, return_tensors='pt', truncation=True)\n","            input_code_tensor = encoded_inputs.input_ids.to(device)\n","\n","            encoded_targets = tokenizer(tokenized_correct, padding='max_length', max_length=150, return_tensors='pt', truncation=True)\n","            target_code_tensor = encoded_targets.input_ids.to(device)\n","\n","            input_code_tensors.append(input_code_tensor)\n","            target_code_tensors.append(target_code_tensor)\n","\n","        # Create batch tensors\n","        input_code_tensors = torch.cat(input_code_tensors, dim=0)\n","        target_code_tensors = torch.cat(target_code_tensors, dim=0)\n","\n","        attention_masks = torch.where(input_code_tensors != 0, torch.tensor(1), input_code_tensors)\n","\n","        # Clear gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(input_ids=input_code_tensors, attention_mask=attention_masks, labels=target_code_tensors)\n","        loss = outputs.loss\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update parameters\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Save model checkpoint at every epoch\n","    #TODO REPLACE WITH TARGET SAVE LOCATION FOR THE MODEL .PT FILE\n","    torch.save(model.state_dict(), f\"/PATH/TO/pegasusModel.pt\")\n","\n","    average_loss = total_loss / num_batches\n","    print(f\"Saved: Epoch {epoch+1}: Average Loss = {average_loss}\")\n","    average_losses.append(average_loss)\n","\n","    #write epoch training loss to file\n","    with open(loss_file, \"a\") as f:\n","        f.write(str(average_loss) + \", \\n\")\n","\n","print(\"Average training loss:\")\n","print(average_losses)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:34:55.296265Z","iopub.status.busy":"2023-09-19T15:34:55.295737Z"},"trusted":true},"outputs":[],"source":["#Inference\n","\n","from transformers import AutoTokenizer, PegasusForConditionalGeneration\n","import torch\n","import pandas as pd\n","import evaluate\n","\n","# Check if a GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load Pegasus tokenizer and model\n","pegasus_tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\n","pegasus_model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n","\n","# Load the saved model checkpoint\n","#TODO: REPLACE THE FOLLOWING WITH MODEL PATH\n","model_checkpoint_path = \"/PATH/TO/pegasusModel.pt\"\n","pegasus_model.load_state_dict(torch.load(model_checkpoint_path, map_location=device))  # Use map_location to ensure it's loaded to the correct device\n","pegasus_model.to(device)  # Move the model to the correct device (GPU or CPU)\n","pegasus_model.eval()\n","\n","# Load  test.tsv file\n","#TODO: REPLACE WITH TEST DATASET PATH\n","test_file_path = \"/PATH/TO/Test.tsv\"  # Replace with the actual file path\n","df = pd.read_csv(test_file_path, sep='\\t')\n","\n","total_score = 0\n","num_iterations = 0\n","\n","# Create an output file for writing\n","# TODO: Specify the path where you want to save the file\n","output_file_path = \"output_predictions.txt\"  \n","with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n","    for index, row in df.iterrows():\n","        # Sample input text\n","        sample_input = row[\"fix\"]\n","\n","        # Tokenize the input text\n","        input_ids = pegasus_tokenizer.encode(sample_input, return_tensors=\"pt\")\n","\n","        # Move inputs to the correct device (GPU or CPU)\n","        input_ids = input_ids.to(device)\n","\n","        # Perform inference\n","        with torch.no_grad():\n","            output = pegasus_model.generate(input_ids, max_length=150, num_beams=5, early_stopping=True)\n","\n","        # Convert the output token IDs back to text\n","        output_text = pegasus_tokenizer.decode(output[0], skip_special_tokens=True)\n","        target_text = row[\"bug\"]\n","\n","        # Calculate CHRF score\n","        prediction = [output_text]\n","        reference = [[target_text]]\n","        chrf = evaluate.load(\"chrf\")\n","        results = chrf.compute(predictions=prediction, references=reference)\n","        score = results[\"score\"]\n","        # Print the output\n","        print(\"Round:\", index)\n","        print(\"Score:\", score)\n","        print()\n","\n","        # Write the predictions to the output file\n","        output_file.write(\"Round: {}\\n\".format(index))\n","        output_file.write(\"Input: {}\\n\".format(sample_input))\n","        output_file.write(\"Output: {}\\n\".format(output_text))\n","        output_file.write(\"Target: {}\\n\".format(target_text))\n","        output_file.write(\"CHRF Score: {}\\n\".format(score))\n","        output_file.write(\"\\n\")  # Add a blank line between entries\n","        \n","        total_score = total_score + score\n","        num_iterations = num_iterations + 1\n","\n","print(\"Predictions saved to:\", output_file_path)\n","print(\"Average CHRF score:\", total_score/num_iterations)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
