{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-21T15:31:04.455520Z","iopub.status.busy":"2023-09-21T15:31:04.454912Z","iopub.status.idle":"2023-09-21T15:31:18.800287Z","shell.execute_reply":"2023-09-21T15:31:18.799137Z","shell.execute_reply.started":"2023-09-21T15:31:04.455484Z"},"trusted":true},"outputs":[],"source":["!pip install transformers sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T15:31:18.803159Z","iopub.status.busy":"2023-09-21T15:31:18.802784Z","iopub.status.idle":"2023-09-21T15:31:30.495989Z","shell.execute_reply":"2023-09-21T15:31:30.494828Z","shell.execute_reply.started":"2023-09-21T15:31:18.803123Z"},"trusted":true},"outputs":[],"source":["!pip install torchtext==0.6.0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T15:31:30.499565Z","iopub.status.busy":"2023-09-21T15:31:30.498809Z","iopub.status.idle":"2023-09-21T15:31:42.630026Z","shell.execute_reply":"2023-09-21T15:31:42.628846Z","shell.execute_reply.started":"2023-09-21T15:31:30.499525Z"},"trusted":true},"outputs":[],"source":["!pip install evaluate sacrebleu"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-02T08:55:59.522967Z","iopub.status.busy":"2023-09-02T08:55:59.522658Z","iopub.status.idle":"2023-09-02T08:55:59.531080Z","shell.execute_reply":"2023-09-02T08:55:59.529919Z","shell.execute_reply.started":"2023-09-02T08:55:59.522940Z"},"trusted":true},"outputs":[],"source":["# Specify the filename of loss file txt\n","output_filename = \"averageLosses.txt\"\n","\n","# Open the file in write mode\n","with open(output_filename, \"w\") as f:\n","    # Write a space character to the file\n","    f.write(\" \")\n","\n","print(f\"A space character has been written to {output_filename}.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T14:41:49.118556Z","iopub.status.busy":"2023-08-26T14:41:49.118019Z","iopub.status.idle":"2023-08-26T14:43:06.132532Z","shell.execute_reply":"2023-08-26T14:43:06.130988Z","shell.execute_reply.started":"2023-08-26T14:41:49.118512Z"},"trusted":true},"outputs":[],"source":["#Training Code\n","\n","from transformers import AutoTokenizer, ProphetNetForConditionalGeneration, AdamW\n","import torch\n","import csv\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Check if a GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Read data from train.tsv and create training examples\n","training_examples = []\n","\n","#TODO: REPLACE FOLLOWING WITH TRAINING DATA (TSV FILE) PATH\n","with open('/PATH/TO/TRAINING.TSV', 'r') as tsvfile:\n","    reader = csv.reader(tsvfile, delimiter='\\t')\n","    next(reader)  # Skip header row\n","    for row in reader:\n","        fixed_sentence = row[0]\n","        buggy_sentence = row[1]\n","        training_examples.append((fixed_sentence, buggy_sentence))\n","\n","# Load ProphetNet tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n","model = ProphetNetForConditionalGeneration.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n","\n","# Move models to GPU\n","model.to(device)\n","\n","# Define optimizer and loss function\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","#TODO: REPLACE THE FOLLOWING WITH LOSS FILE TXT PATH\n","loss_file = \"/PATH/TO/averageLosses.txt\"\n","\n","load = False\n","if load:\n","    #TODO: REPLACE THE FOLLOWING WITH MODEL TRAINING CHECKPOINT .PT FILE\n","    model.load_state_dict(torch.load(\"/PATH/TO/ProphetNetModel.pt\"))\n","\n","# Training loop\n","batch_size = 16\n","average_losses = []\n","for epoch in range(30):  # Number of epochs\n","    total_loss = 0.0\n","\n","    tokenized_example_subset = training_examples\n","\n","    # Shuffle the tokenized examples\n","    np.random.shuffle(tokenized_example_subset)\n","\n","    num_batches = len(tokenized_example_subset) // batch_size\n","\n","    for batch_idx in tqdm(range(num_batches), desc=f\"Epoch {epoch+1}\"):\n","        start_idx = batch_idx * batch_size\n","        end_idx = start_idx + batch_size\n","\n","        batch_examples = tokenized_example_subset[start_idx:end_idx]\n","\n","        input_code_tensors = []\n","        target_code_tensors = []\n","\n","        for example in batch_examples:\n","            tokenized_incorrect, tokenized_correct = example\n","\n","            # Tokenize using the ProphetNet tokenizer\n","            encoded_inputs = tokenizer(tokenized_incorrect, padding='max_length', max_length=128, return_tensors='pt', truncation=True)\n","            input_code_tensor = encoded_inputs.input_ids.to(device)\n","\n","            encoded_targets = tokenizer(tokenized_correct, padding='max_length', max_length=128, return_tensors='pt', truncation=True)\n","            target_code_tensor = encoded_targets.input_ids.to(device)\n","\n","            input_code_tensors.append(input_code_tensor)\n","            target_code_tensors.append(target_code_tensor)\n","\n","        # Create batch tensors\n","        input_code_tensors = torch.cat(input_code_tensors, dim=0)\n","        target_code_tensors = torch.cat(target_code_tensors, dim=0)\n","\n","        # Clear gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(input_ids=input_code_tensors, labels=target_code_tensors)\n","        loss = outputs.loss\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update parameters\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Save model checkpoint at every epoch\n","    #TODO REPLACE WITH TARGET SAVE LOCATION FOR THE MODEL .PT FILE\n","    torch.save(model.state_dict(), f\"/PATH/TO/ProphetNetModel.pt\")\n","\n","    average_loss = total_loss / num_batches\n","    print(f\"Saved: Epoch {epoch+1}: Average Loss = {average_loss}\")\n","    average_losses.append(average_loss)\n","\n","    with open(loss_file, \"a\") as f:\n","      f.write(str(average_loss) + \", \\n\")\n","\n","print(\"Average training loss:\")\n","print(average_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-21T15:31:42.634088Z","iopub.status.busy":"2023-09-21T15:31:42.633789Z"},"trusted":true},"outputs":[],"source":["#Inference Code\n","\n","from transformers import AutoTokenizer, ProphetNetForConditionalGeneration\n","import torch\n","import pandas as pd\n","import evaluate\n","\n","# Check if a GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load Prophetnet tokenizer and model\n","prophetnet_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n","\n","prophetnet_model = ProphetNetForConditionalGeneration.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n","\n","# Load the saved model checkpoint\n","#TODO: REPLACE THE FOLLOWING WITH MODEL PATH\n","model_checkpoint_path = \"/PATH/TO/prophetnet_model.pt\"\n","try:\n","    prophetnet_model.load_state_dict(torch.load(model_checkpoint_path, map_location=device))\n","    prophetnet_model.to(device)\n","    prophetnet_model.eval()\n","except FileNotFoundError:\n","    print(\"Model checkpoint not found.\")\n","    exit(1)\n","\n","# Load  test.tsv file\n","#TODO: REPLACE WITH TEST DATASET PATH\n","test_file_path = \"/PATH/TO/Test.tsv\" \n","df = pd.read_csv(test_file_path, sep='\\t')\n","\n","total_score = 0\n","num_iterations = 0\n","\n","# Create a text file for writing\n","output_file_path = \"output_predictions.txt\"  # Specify the path where you want to save the file\n","with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n","    # Iterate through the \"fix\" column and generate predictions\n","    for index, row in df.iterrows():\n","        sample_input = row[\"fix\"]\n","        target_text = row[\"bug\"]\n","\n","        input_ids = prophetnet_tokenizer.encode(sample_input, return_tensors=\"pt\")\n","\n","        input_ids = input_ids.to(device)\n"," \n","        with torch.no_grad():\n","            output = prophetnet_model.generate(input_ids, max_length=1000, num_beams=5, early_stopping=True)\n","\n","        output_text = prophetnet_tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","        # Calculate CHRF score\n","        prediction = [output_text]\n","        reference = [[target_text]]\n","        chrf = evaluate.load(\"chrf\")\n","        results = chrf.compute(predictions=prediction, references=reference)\n","        score = results[\"score\"]\n","        # Print the output\n","        print(\"Round:\", index)\n","        print(\"Score:\", score)\n","        print()\n","        \n","        # Write the data to the output file\n","        output_file.write(\"Round: {}\\n\".format(index))\n","        output_file.write(\"Input: {}\\n\".format(sample_input))\n","        output_file.write(\"Output: {}\\n\".format(output_text))\n","        output_file.write(\"Target: {}\\n\".format(target_text))\n","        output_file.write(\"CHRF Score: {}\\n\".format(score))\n","        output_file.write(\"\\n\")  # Add a blank line between entries\n","\n","        total_score = total_score + score\n","        num_iterations = num_iterations + 1\n","\n","print(\"Predictions saved to:\", output_file_path)\n","print(\"Average CHRF score:\", total_score/num_iterations)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
