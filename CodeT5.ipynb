{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install transformers sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install torchtext==0.6.0"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install evaluate sacrebleu"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Specify the filename of loss file txt\n","output_filename = \"averageLosses.txt\"\n","\n","# Open the file in write mode\n","with open(output_filename, \"w\") as f:\n","    # Write a space character to the file\n","    f.write(\" \")\n","\n","print(f\"A space character has been written to {output_filename}.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Training Code\n","\n","from transformers import RobertaTokenizer, T5ForConditionalGeneration, AdamW\n","import torch\n","import csv\n","import torch.nn.functional as F\n","import numpy as np\n","from tqdm.notebook import tqdm \n","\n","# Check if a GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Read data from train.tsv and create training examples\n","training_examples = []\n","\n","#TODO: REPLACE FOLLOWING WITH TRAINING DATA (TSV FILE) PATH\n","with open('/PATH/TO/TRAINING.TSV', 'r') as tsvfile:\n","    reader = csv.reader(tsvfile, delimiter='\\t')\n","    next(reader)  # Skip header row\n","    for row in reader:\n","        fixed_sentence = row[0]\n","        buggy_sentence = row[1]\n","        training_examples.append((fixed_sentence, buggy_sentence))\n","\n","# Load codeT5 tokenizer and model\n","t5_tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n","t5_model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n","\n","# Move models to GPU\n","t5_model.to(device)\n","\n","# Set pad token ID\n","t5_model.config.pad_token_id = t5_model.config.eos_token_id\n","\n","# Define optimizer and loss function\n","optimizer = AdamW(t5_model.parameters(), lr=1e-5)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","#TODO: REPLACE THE FOLLOWING WITH LOSS FILE TXT PATH\n","loss_file = \"/PATH/TO/averageLosses.txt\"\n","\n","load = False\n","if load:\n","    #TODO: REPLACE THE FOLLOWING WITH MODEL TRAINING CHECKPOINT .PT FILE\n","    t5_model.load_state_dict(torch.load(\"/PATH/TO/CodeT5Model.pt\"))\n","\n","# Training loop\n","batch_size = 16\n","average_losses = []\n","for epoch in range(30):  # Number of epochs\n","    total_loss = 0.0\n","\n","    tokenized_example_subset = training_examples\n","\n","    # Shuffle the tokenized examples\n","    np.random.shuffle(tokenized_example_subset)\n","\n","    num_batches = len(tokenized_example_subset) // batch_size\n","\n","    for batch_idx in tqdm(range(num_batches), desc=f\"Epoch {epoch+1}\"):\n","        start_idx = batch_idx * batch_size\n","        end_idx = start_idx + batch_size\n","\n","        batch_examples = tokenized_example_subset[start_idx:end_idx]\n","\n","        input_code_tensors = []\n","        target_code_tensors = []\n","\n","        for example in batch_examples:\n","            tokenized_incorrect, tokenized_correct = example\n","\n","            # Tokenize using the T5 tokenizer\n","            encoded_inputs = t5_tokenizer(tokenized_incorrect, padding='max_length', max_length=512, return_tensors='pt', truncation=True)\n","            input_code_tensor = encoded_inputs.input_ids.to(device)\n","            \n","            encoded_targets = t5_tokenizer(tokenized_correct, padding='max_length', max_length=512, return_tensors='pt', truncation=True)\n","            target_code_tensor = encoded_targets.input_ids.to(device)\n","\n","            input_code_tensors.append(input_code_tensor)\n","            target_code_tensors.append(target_code_tensor)\n","\n","        # Create batch tensors\n","        input_code_tensors = torch.cat(input_code_tensors, dim=0)\n","        target_code_tensors = torch.cat(target_code_tensors, dim=0)\n","\n","        # Create attention mask\n","        attention_masks = torch.where(input_code_tensors != 0, torch.tensor(1), input_code_tensors)\n","\n","        # Clear gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = t5_model(input_ids=input_code_tensors, attention_mask=attention_masks, labels=target_code_tensors)\n","        loss = outputs.loss\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update parameters\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Save model checkpoint at every epoch\n","    #TODO REPLACE WITH TARGET SAVE LOCATION FOR THE MODEL .PT FILE\n","    torch.save(t5_model.state_dict(), f\"/PATH/TO/CodeT5Model.pt\")\n","\n","    average_loss = total_loss / num_batches\n","    print(f\"Saved: Epoch {epoch+1}: Average Loss = {average_loss}\")\n","    average_losses.append(average_loss)\n","\n","    #write epoch training loss to file\n","    with open(loss_file, \"a\") as f:\n","      f.write(str(average_loss) + \", \\n\")\n","\n","print(\"Average training loss:\")\n","print(average_losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Inference Code\n","\n","from transformers import RobertaTokenizer, T5ForConditionalGeneration\n","import torch\n","import pandas as pd\n","import evaluate\n","\n","# Check GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Custom tokens (if needed)\n","custom_tokens = []\n","\n","# Load tokenizer and pre-trained model\n","t5_tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n","t5_model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n","\n","# Add custom tokens to the tokenizer\n","t5_tokenizer.add_tokens(custom_tokens)\n","t5_model.resize_token_embeddings(len(t5_tokenizer))\n","\n","# Load the saved model checkpoint\n","#TODO: REPLACE THE FOLLOWING WITH MODEL PATH\n","model_checkpoint_path = \"/PATH/TO/CodeT5Model.pt\"\n","t5_model.load_state_dict(torch.load(model_checkpoint_path, map_location=device))  # Use map_location to ensure it's loaded to the correct device\n","t5_model.to(device)  # Move the model to the correct device (GPU or CPU)\n","t5_model.eval()\n","\n","# Load  test.tsv file\n","#TODO: REPLACE WITH TEST DATASET PATH\n","test_file_path = \"/PATH/TO/Test.tsv\" \n","df = pd.read_csv(test_file_path, sep='\\t')\n","total_score = 0\n","num_iterations = 0\n","\n","# output file for writing for writing loss\n","# TODO: Specify the path where you want to save the file\n","output_file_path = \"output_predictions.txt\"\n","with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n","    for index, row in df.iterrows():\n","        #input text\n","        input_code = row[\"fix\"]\n","\n","        # Tokenize the input text\n","        input_ids = t5_tokenizer.encode(input_code, return_tensors=\"pt\")\n","\n","        # Move inputs to the correct device (GPU or CPU)\n","        input_ids = input_ids.to(device)\n","\n","        # Perform inference\n","        with torch.no_grad():\n","            output = t5_model.generate(input_ids, max_length=1000, num_beams=5, early_stopping=True)\n","\n","        # Convert the output token IDs back to text\n","        output_code = t5_tokenizer.decode(output[0], skip_special_tokens=True)\n","        target_code = row[\"bug\"]\n","        \n","        prediction = [output_code]\n","        reference = [[target_code]]\n","        \n","        # Calculate CHRF score\n","        chrf = evaluate.load(\"chrf\")\n","        results = chrf.compute(predictions=prediction, references=reference)\n","        score = results[\"score\"]\n","        \n","        # Print the output\n","        print(\"Round:\", index)\n","        print(\"Chrf Score:\", score)\n","        print()\n","\n","        # Write the data to the output file\n","        output_file.write(\"Round: {}\\n\".format(index))\n","        output_file.write(\"Input: {}\\n\".format(input_code))\n","        output_file.write(\"Output: {}\\n\".format(output_code))\n","        output_file.write(\"Target: {}\\n\".format(target_code))\n","        output_file.write(\"CHRF Score: {}\\n\".format(score))\n","        output_file.write(\"\\n\")  # Add a blank line between entries\n","        \n","        total_score = total_score + score\n","        num_iterations = num_iterations + 1\n","\n","print(\"Predictions saved to:\", output_file_path)\n","print(\"Average CHRF score:\", total_score/num_iterations)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
